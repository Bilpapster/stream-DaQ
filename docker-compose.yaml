networks:
  data-quality-network:

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    hostname: zookeeper
    container_name: zookeeper
    networks:
      - data-quality-network
    ports:
      - "22181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:6.2.0
    hostname: kafka
    container_name: kafka
    networks:
      - data-quality-network
    volumes:
      - ./kafka/scripts:/app/scripts  # contains the script to create the kafka topics
    ports:
      - "29092:29092"
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      TOPIC_TIMESTAMP_TYPE: 'CreateTime'
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
    depends_on:
      - zookeeper
    env_file:
      - .env

  stream:
    build:
      context: .
      dockerfile: dockerfiles/stream.Dockerfile
    container_name: stream
    depends_on:
      - kafka
    networks:
      - data-quality-network
    environment:
      - INPUT_TOPIC=${INPUT_TOPIC}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - WINDOW_DURATION=${WINDOW_DURATION}
      - MESSAGES_PER_WINDOW=${MESSAGES_PER_WINDOW}
    env_file:
      - .env
    volumes:
      - ./stream/datasets:/app/datasets:ro
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: "4.0"

  deequ:
    build:
      context: .
      dockerfile: dockerfiles/deequ.Dockerfile
    container_name: deequ
    depends_on:
      - kafka
    networks:
      - data-quality-network
    environment:
      - SPARK_MASTER=${SPARK_MASTER}
      - SPARK_NUM_CORES=${SPARK_NUM_CORES}
    env_file:
      - .env
    volumes:
      - ./execution-results/deequ:/app/executionData
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: "4.0"

  deequ-reddit:
    build:
      context: .
      dockerfile: dockerfiles/deequ-reddit.Dockerfile
    container_name: deequ-reddit
    depends_on:
      - kafka
    networks:
      - data-quality-network
    environment:
      - SPARK_MASTER=${SPARK_MASTER}
      - SPARK_NUM_CORES=${SPARK_NUM_CORES}
    env_file:
      - .env
    volumes:
      - ./execution-results/deequ:/app/executionData
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: "4.0"

  daq:
    build:
      context: .
      dockerfile: dockerfiles/daq.Dockerfile
    container_name: daq
    depends_on:
      - kafka
      - output-consumer
    networks:
      - data-quality-network
    environment:
      - INPUT_TOPIC=${INPUT_TOPIC}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
    env_file:
      - .env
    volumes:
      - ./execution-results/stream-daq:/app/data
    deploy:
      resources:
        limits:
          memory: 16G
          cpus: "8.0"

  output-consumer:
    build:
      context: .
      dockerfile: dockerfiles/output-consumer.Dockerfile
    container_name: output-consumer
    depends_on:
      - kafka
    networks:
      - data-quality-network
    environment:
      - OUTPUT_TOPIC=${OUTPUT_TOPIC}
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
    volumes:
      - ./execution-results/stream-daq:/app/data
    env_file:
      - .env
